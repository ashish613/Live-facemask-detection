{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "facemask detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashish613/Live-facemask-detection/blob/main/facemask_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU3-IKqA3YnR",
        "outputId": "054fefbf-7d7f-4d12-9ee6-5ea1ac2cac0d"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFele16Z3g9g",
        "outputId": "4621f57d-438e-4da4-ccd8-06633f60099a"
      },
      "source": [
        "pip install tensorflow==2.1.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 39kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.19.5)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.36.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.32.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.15.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.2)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 41.9MB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.10.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.12.4)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (51.3.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=077acb7741174e7cfcf3dc2a9a35f0652d9fc4e6f77810ab07df882bdde70425\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, keras-applications, gast, tensorflow\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.4.0\n",
            "    Uninstalling tensorflow-2.4.0:\n",
            "      Successfully uninstalled tensorflow-2.4.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3TAvJ8l3nF7",
        "outputId": "337607d8-0596-4a48-d1d5-ab802ed6ec91"
      },
      "source": [
        "pip install keras==2.3.1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
            "\r\u001b[K     |▉                               | 10kB 15.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 10.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 7.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 7.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 5.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.19.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.1) (1.15.0)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo4BdXsx66JV"
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\r\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "from imutils.video import VideoStream\r\n",
        "import numpy as np\r\n",
        "import argparse\r\n",
        "import imutils\r\n",
        "import time\r\n",
        "import cv2\r\n",
        "import os"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBBpuy4jrovY"
      },
      "source": [
        "model = load_model('/content/drive/MyDrive/Colab Notebooks/face mask detection/facemask_detection_model/facemask_detection_model.h5') # cnn\n",
        " \n",
        "# model accept below hight and width of the image\n",
        "img_width, img_hight = 200, 200\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSzfswUFVfyy"
      },
      "source": [
        "faceNet=cv2.dnn.readNet('/content/drive/MyDrive/Colab Notebooks/tomato/deploy.prototxt','/content/drive/MyDrive/Colab Notebooks/tomato/res10_300x300_ssd_iter_140000.caffemodel')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1BCw_bvJKoj"
      },
      "source": [
        "def detect_and_predict_mask(frame, faceNet, maskNet):\r\n",
        "\t# grab the dimensions of the frame and then construct a blob\r\n",
        "\t# from it\r\n",
        "\t(h, w) = frame.shape[:2]\r\n",
        "\tblob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300),\r\n",
        "\t\t(104.0, 177.0, 123.0))\r\n",
        "\r\n",
        "\t# pass the blob through the network and obtain the face detections\r\n",
        "\tfaceNet.setInput(blob)\r\n",
        "\tdetections = faceNet.forward()\r\n",
        "\r\n",
        "\t# initialize our list of faces, their corresponding locations,\r\n",
        "\t# and the list of predictions from our face mask network\r\n",
        "\tfaces = []\r\n",
        "\tlocs = []\r\n",
        "\tpreds = []\r\n",
        "\r\n",
        "\t# loop over the detections\r\n",
        "\tfor i in range(0, detections.shape[2]):\r\n",
        "\t\t# extract the confidence (i.e., probability) associated with\r\n",
        "\t\t# the detection\r\n",
        "\t\tconfidence = detections[0, 0, i, 2]\r\n",
        "\r\n",
        "\t\t# filter out weak detections by ensuring the confidence is\r\n",
        "\t\t# greater than the minimum confidence\r\n",
        "\t\tif confidence > args[\"confidence\"]:\r\n",
        "\t\t\t# compute the (x, y)-coordinates of the bounding box for\r\n",
        "\t\t\t# the object\r\n",
        "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\r\n",
        "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\r\n",
        "\r\n",
        "\t\t\t# ensure the bounding boxes fall within the dimensions of\r\n",
        "\t\t\t# the frame\r\n",
        "\t\t\t(startX, startY) = (max(0, startX), max(0, startY))\r\n",
        "\t\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\r\n",
        "\r\n",
        "\t\t\t# extract the face ROI, convert it from BGR to RGB channel\r\n",
        "\t\t\t# ordering, resize it to 224x224, and preprocess it\r\n",
        "\t\t\tface = frame[startY:endY, startX:endX]\r\n",
        "\t\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\r\n",
        "\t\t\tface = cv2.resize(face, (224, 224))\r\n",
        "\t\t\tface = img_to_array(face)\r\n",
        "\t\t\tface = preprocess_input(face)\r\n",
        "\r\n",
        "\t\t\t# add the face and bounding boxes to their respective\r\n",
        "\t\t\t# lists\r\n",
        "\t\t\tfaces.append(face)\r\n",
        "\t\t\tlocs.append((startX, startY, endX, endY))\r\n",
        "\r\n",
        "\t# only make a predictions if at least one face was detected\r\n",
        "\tif len(faces) > 0:\r\n",
        "\t\t# for faster inference we'll make batch predictions on *all*\r\n",
        "\t\t# faces at the same time rather than one-by-one predictions\r\n",
        "\t\t# in the above `for` loop\r\n",
        "\t\tfaces = np.array(faces, dtype=\"float32\")\r\n",
        "\t\tpreds = maskNet.predict(faces, batch_size=32)\r\n",
        "\r\n",
        "\t# return a 2-tuple of the face locations and their corresponding\r\n",
        "\t# locations\r\n",
        "\treturn (locs, preds)\r\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuMv6B4oJQB1"
      },
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\r\n",
        "def video_stream():\r\n",
        "  js = Javascript('''\r\n",
        "    var video;\r\n",
        "    var div = null;\r\n",
        "    var stream;\r\n",
        "    var captureCanvas;\r\n",
        "    var imgElement;\r\n",
        "    var labelElement;    \r\n",
        "    var pendingResolve = null;\r\n",
        "    var shutdown = false;\r\n",
        "    \r\n",
        "    function removeDom() {\r\n",
        "       stream.getVideoTracks()[0].stop();\r\n",
        "       video.remove();\r\n",
        "       div.remove();\r\n",
        "       video = null;\r\n",
        "       div = null;\r\n",
        "       stream = null;\r\n",
        "       imgElement = null;\r\n",
        "       captureCanvas = null;\r\n",
        "       labelElement = null;\r\n",
        "    }\r\n",
        "    \r\n",
        "    function onAnimationFrame() {\r\n",
        "      if (!shutdown) {\r\n",
        "        window.requestAnimationFrame(onAnimationFrame);\r\n",
        "      }\r\n",
        "      if (pendingResolve) {\r\n",
        "        var result = \"\";\r\n",
        "        if (!shutdown) {\r\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\r\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\r\n",
        "        }\r\n",
        "        var lp = pendingResolve;\r\n",
        "        pendingResolve = null;\r\n",
        "        lp(result);\r\n",
        "      }\r\n",
        "    }\r\n",
        "    \r\n",
        "    async function createDom() {\r\n",
        "      if (div !== null) {\r\n",
        "        return stream;\r\n",
        "      }\r\n",
        "\r\n",
        "      div = document.createElement('div');\r\n",
        "      div.style.border = '2px solid black';\r\n",
        "      div.style.padding = '3px';\r\n",
        "      div.style.width = '100%';\r\n",
        "      div.style.maxWidth = '600px';\r\n",
        "      document.body.appendChild(div);\r\n",
        "      \r\n",
        "      const modelOut = document.createElement('div');\r\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\r\n",
        "      labelElement = document.createElement('span');\r\n",
        "      labelElement.innerText = 'No data';\r\n",
        "      labelElement.style.fontWeight = 'bold';\r\n",
        "      modelOut.appendChild(labelElement);\r\n",
        "      div.appendChild(modelOut);\r\n",
        "           \r\n",
        "      video = document.createElement('video');\r\n",
        "      video.style.display = 'block';\r\n",
        "      video.width = div.clientWidth - 6;\r\n",
        "      video.setAttribute('playsinline', '');\r\n",
        "      video.onclick = () => { shutdown = true; };\r\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\r\n",
        "          {video: { facingMode: \"environment\"}});\r\n",
        "      div.appendChild(video);\r\n",
        "\r\n",
        "      imgElement = document.createElement('img');\r\n",
        "      imgElement.style.position = 'absolute';\r\n",
        "      imgElement.style.zIndex = 1;\r\n",
        "      imgElement.onclick = () => { shutdown = true; };\r\n",
        "      div.appendChild(imgElement);\r\n",
        "      \r\n",
        "      const instruction = document.createElement('div');\r\n",
        "      instruction.innerHTML = \r\n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\r\n",
        "          'When finished, click here or on the video to stop this demo</span>';\r\n",
        "      div.appendChild(instruction);\r\n",
        "      instruction.onclick = () => { shutdown = true; };\r\n",
        "      \r\n",
        "      video.srcObject = stream;\r\n",
        "      await video.play();\r\n",
        "\r\n",
        "      captureCanvas = document.createElement('canvas');\r\n",
        "      captureCanvas.width = 640; //video.videoWidth;\r\n",
        "      captureCanvas.height = 480; //video.videoHeight;\r\n",
        "      window.requestAnimationFrame(onAnimationFrame);\r\n",
        "      \r\n",
        "      return stream;\r\n",
        "    }\r\n",
        "    async function stream_frame(label, imgData) {\r\n",
        "      if (shutdown) {\r\n",
        "        removeDom();\r\n",
        "        shutdown = false;\r\n",
        "        return '';\r\n",
        "      }\r\n",
        "\r\n",
        "      var preCreate = Date.now();\r\n",
        "      stream = await createDom();\r\n",
        "      \r\n",
        "      var preShow = Date.now();\r\n",
        "      if (label != \"\") {\r\n",
        "        labelElement.innerHTML = label;\r\n",
        "      }\r\n",
        "            \r\n",
        "      if (imgData != \"\") {\r\n",
        "        var videoRect = video.getClientRects()[0];\r\n",
        "        imgElement.style.top = videoRect.top + \"px\";\r\n",
        "        imgElement.style.left = videoRect.left + \"px\";\r\n",
        "        imgElement.style.width = videoRect.width + \"px\";\r\n",
        "        imgElement.style.height = videoRect.height + \"px\";\r\n",
        "        imgElement.src = imgData;\r\n",
        "      }\r\n",
        "      \r\n",
        "      var preCapture = Date.now();\r\n",
        "      var result = await new Promise(function(resolve, reject) {\r\n",
        "        pendingResolve = resolve;\r\n",
        "      });\r\n",
        "      shutdown = false;\r\n",
        "      \r\n",
        "      return {'create': preShow - preCreate, \r\n",
        "              'show': preCapture - preShow, \r\n",
        "              'capture': Date.now() - preCapture,\r\n",
        "              'img': result};\r\n",
        "    }\r\n",
        "    ''')\r\n",
        "\r\n",
        "  display(js)\r\n",
        "  \r\n",
        "def video_frame(label, bbox):\r\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\r\n",
        "  return data\r\n",
        "  "
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjkUlv8hNP6P"
      },
      "source": [
        "def js_reply_to_image(js_reply):\r\n",
        "  \"\"\"\r\n",
        "  input:\r\n",
        "        js_reply = javascript object contain image from webcam\r\n",
        "  output:\r\n",
        "        image array = image rgb array of size 512 * 512 from webcam\r\n",
        "  \"\"\"\r\n",
        "  jpeg_bytes = base64.b64decode(js.reply['img'].split(',')[1])\r\n",
        "  image_PIL = image.open(io.Bytes.IO(jpeg_bytes))\r\n",
        "  image_array = np.array(image_PIL)\r\n",
        "\r\n",
        "  return image_array\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "2CIAjRJVO93x",
        "outputId": "eee85aff-9071-4036-d8d4-eb572421f170"
      },
      "source": [
        "# start streaming video from webcam\r\n",
        "start_input()\r\n",
        "label_html = 'Capturing...'\r\n",
        "img_data = ''\r\n",
        "count = 0 \r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "while True:\r\n",
        "  js_reply = video_frame(label_html, bbox)\r\n",
        "  if not js_reply:\r\n",
        "    break\r\n",
        "  image = js_reply_to_image(js_reply)\r\n",
        "  frame=image\r\n",
        "  v==True\r\n",
        "  if v==True:\r\n",
        "    frame = imutils.resize(frame, width=400)\r\n",
        "    (locs, preds) = detect_and_predict_mask(frame, faceNet, model)\r\n",
        "    for(box, pred) in zip(locs, preds):\r\n",
        "\t\t   (startX, startY, endX, endY) = box\r\n",
        "\t\t   (mask, withoutMask) = pred\r\n",
        "\t\t   label = \"Mask\" if mask > withoutMask else \"No Mask\"\r\n",
        "\t\t   color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\r\n",
        "\t\t   label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\r\n",
        "\t\t   frame=cv2.putText(frame, label, (startX, startY-10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\r\n",
        "       frame=cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\r\n",
        "\r\n",
        "       cv2_imshow(frame)\r\n",
        "          "
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-68-4fb16d257b7e>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    frame=cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\u001b[0m\n\u001b[0m                                                                        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "wy-J2RI3c7kz",
        "outputId": "4b2488cc-9e01-4808-adfc-621217ea528f"
      },
      "source": [
        "# start streaming video from webcam\r\n",
        "start_input()\r\n",
        "# label for video\r\n",
        "label_html = 'Capturing...'\r\n",
        "img_data = ''\r\n",
        "count = 0 \r\n",
        "while True:\r\n",
        "\t# grab the frame from the threaded video stream and resize it\r\n",
        "\t# to have a maximum width of 400 pixels\r\n",
        "\tframe = vs.read()\r\n",
        "\tframe = imutils.resize(frame, width=400)\r\n",
        "\r\n",
        "\t# detect faces in the frame and determine if they are wearing a\r\n",
        "\t# face mask or not\r\n",
        "\t(locs, preds) = detect_and_predict_mask(frame, faceNet, maskNet)\r\n",
        "\r\n",
        "\t# loop over the detected face locations and their corresponding\r\n",
        "\t# locations\r\n",
        "\tfor (box, pred) in zip(locs, preds):\r\n",
        "\t\t# unpack the bounding box and predictions\r\n",
        "\t\t(startX, startY, endX, endY) = box\r\n",
        "\t\t(mask, withoutMask) = pred\r\n",
        "\r\n",
        "\t\t# determine the class label and color we'll use to draw\r\n",
        "\t\t# the bounding box and text\r\n",
        "\t\tlabel = \"Mask\" if mask > withoutMask else \"No Mask\"\r\n",
        "\t\tcolor = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\r\n",
        "\r\n",
        "\t\t# include the probability in the label\r\n",
        "\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\r\n",
        "\r\n",
        "\t\t# display the label and bounding box rectangle on the output\r\n",
        "\t\t# frame\r\n",
        "\t\tcv2.putText(frame, label, (startX, startY - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\r\n",
        "\t\tcv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\r\n",
        "\r\n",
        "\t# show the output frame\r\n",
        "\tcv2.imshow(\"Frame\", frame)\r\n",
        "\tkey = cv2.waitKey(1) & 0xFF\r\n",
        "\r\n",
        "\t# if the `q` key was pressed, break from the loop\r\n",
        "\tif key == ord(\"q\"):\r\n",
        "\t\tbreak\r\n",
        "\r\n",
        "# do a bit of cleanup\r\n",
        "cv2.destroyAllWindows()\r\n",
        "vs.stop()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-a12f1d1dbd34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# start streaming video from webcam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstart_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# label for video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabel_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Capturing...'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'start_input' is not defined"
          ]
        }
      ]
    }
  ]
}